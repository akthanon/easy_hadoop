#!/bin/bash

# Configuraci√≥n
CHAPTERS_DIR=~/input/chapters
CSV_OUT=~/temas_mobydick.csv
VENV_DIR="$HOME/venv_hadoop"

# Paso 1: Verificar cap√≠tulos
if [ ! -d "$CHAPTERS_DIR" ]; then
    echo "‚ùå Directorio de cap√≠tulos no encontrado. Ejecuta primero el an√°lisis de sentimientos."
    exit 1
fi

# Paso 2: Activar entorno virtual
if [ ! -d "$VENV_DIR" ]; then
    echo "‚ùå Entorno virtual $VENV_DIR no encontrado. Ejecuta primero run_topics.sh"
    exit 1
fi

source "$VENV_DIR/bin/activate"

# Paso 3: Ejecutar an√°lisis de temas
echo "üìö Analizando temas por cap√≠tulo con LDA..."
python3 <<EOF
import os
import pandas as pd
from gensim import corpora, models
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import string

chapter_dir = os.path.expanduser("$CHAPTERS_DIR")
output_csv = os.path.expanduser("$CSV_OUT")

stop_words = set(stopwords.words("english"))
results = []

for fname in sorted(os.listdir(chapter_dir)):
    with open(os.path.join(chapter_dir, fname), encoding="utf-8") as f:
        text = f.read().lower()
        words = word_tokenize(text)
        words = [w for w in words if w not in stop_words and w not in string.punctuation and w.isalpha()]
        if len(words) < 20:
            continue

        dictionary = corpora.Dictionary([words])
        corpus = [dictionary.doc2bow(words)]
        lda = models.LdaModel(corpus, id2word=dictionary, num_topics=1, passes=5)
        top_topic = lda.print_topics(num_words=3)[0][1]
        results.append((fname, top_topic))

df = pd.DataFrame(results, columns=["chapter", "topic"])
df.to_csv(output_csv, index=False)
EOF

deactivate
echo "‚úÖ Resultados guardados en: $CSV_OUT"
